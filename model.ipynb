{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-28T12:33:25.789877Z",
     "start_time": "2024-06-28T12:19:15.298194Z"
    }
   },
   "source": [
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, F1Score\n",
    "\n",
    "# !pip install kaggle\n",
    "# !kaggle datasets download -d quadeer15sh/lfw-facial-recognition\n",
    "#\n",
    "# !unzip -q -u lfw-facial-recognition.zip\n",
    "@keras.saving.register_keras_serializable(package=\"MyLayers\")\n",
    "class DistanceLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, vec1, vec2):\n",
    "        return tf.square(vec1 - vec2)\n",
    "\n",
    "class SiameseNetwork(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Conv2D(32, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size = (2, 2), strides = 1),\n",
    "\n",
    "            layers.Conv2D(32, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size = (2, 2), strides = 1),\n",
    "\n",
    "            layers.Conv2D(32, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size = (2, 2), strides = 1),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation = 'relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(16)\n",
    "        ])\n",
    "        self.get_distance = DistanceLayer()\n",
    "        self.output_layer = layers.Dense(1, activation = 'sigmoid')\n",
    "\n",
    "    def call(self, args):\n",
    "        x1, x2 = args\n",
    "        embedding1, embedding2 = self.encoder(x1), self.encoder(x2)\n",
    "        distance = self.get_distance(embedding1, embedding2)\n",
    "        out = self.output_layer(distance)\n",
    "        return out\n",
    "\n",
    "folder_path = \"./Face Recognition/Faces\"\n",
    "nums = []\n",
    "images = []\n",
    "dictimages = {}\n",
    "images_name = []\n",
    "img_size = 64\n",
    "for i, img_name in tqdm(enumerate(os.listdir(folder_path))):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    img_array = cv2.imread(img_path)\n",
    "    img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "    img_array = img_array[:, :, ::-1] / 255.0\n",
    "    images_name.append(img_name)\n",
    "    dictimages[img_name] = img_array\n",
    "    images.append(img_array)\n",
    "    nums.append(i)\n",
    "images = np.array(images, dtype = 'float32').reshape(-1, img_size, img_size, 3)\n",
    "nums = np.array(nums, dtype = 'float32')\n",
    "images.shape, nums.shape\n",
    "\n",
    "test = pd.read_csv(\"./Face Recognition/test.csv\")\n",
    "trainn = pd.read_csv(\"./Face Recognition/train.csv\")\n",
    "\n",
    "train, val = train_test_split(trainn, test_size=0.2, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X1_test = []\n",
    "X2_test = []\n",
    "y_test = []\n",
    "for i in tqdm(range(len(test['Image1']) - 1)):\n",
    "    X1_test.append(dictimages[test['Image1'][i]])\n",
    "    X2_test.append(dictimages[test['Image2'][i]])\n",
    "    y_test.append(test['class'].apply(lambda x: 1 if x=='similar' else 0)[i])\n",
    "\n",
    "X1_test = np.array(X1_test)\n",
    "X2_test = np.array(X2_test)\n",
    "y_test = np.array(y_test)\n",
    "X1_test.shape, X2_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "X1_train = []\n",
    "X2_train = []\n",
    "y_train = []\n",
    "for i in tqdm(range(len(train['Image1']) - 1)):\n",
    "    X1_train.append(dictimages[train['Image1'][i]])\n",
    "    X2_train.append(dictimages[train['Image2'][i]])\n",
    "    y_train.append(train['class'].apply(lambda x: 1 if x=='similar' else 0)[i])\n",
    "\n",
    "X1_train = np.array(X1_train)\n",
    "X2_train = np.array(X2_train)\n",
    "y_train = np.array(y_train)\n",
    "X1_train.shape, X2_train.shape, y_train.shape\n",
    "\n",
    "X1_val = []\n",
    "X2_val = []\n",
    "y_val = []\n",
    "for i in tqdm(range(len(val['Image1']) - 1)):\n",
    "    X1_val.append(dictimages[val['Image1'][i]])\n",
    "    X2_val.append(dictimages[val['Image2'][i]])\n",
    "    y_val.append(val['class'].apply(lambda x: 1 if x=='similar' else 0)[i])\n",
    "\n",
    "X1_val = np.array(X1_val)\n",
    "X2_val = np.array(X2_val)\n",
    "y_val = np.array(y_val)\n",
    "X1_val.shape, X2_val.shape, y_val.shape\n",
    "\n",
    "X1_test.shape, X2_test.shape, y_test.shape\n",
    "\n",
    "print(X1_train)\n",
    "# X1_train['class']\n",
    "# X1_val['class']\n",
    "\n",
    "model = SiameseNetwork()\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy',Recall()])\n",
    "\n",
    "model.fit([X1_train, X2_train], y_train, epochs = 25, validation_data=([X1_val, X2_val], y_val))\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 09:19:16.461826: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-28 09:19:16.520988: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-28 09:19:16.768404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-28 09:19:17.842388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "13233it [00:14, 899.11it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 3503.05it/s]\n",
      "100%|██████████| 1759/1759 [00:00<00:00, 2073.57it/s]\n",
      "100%|██████████| 439/439 [00:00<00:00, 6317.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.37647059 0.58039216 0.80392157]\n",
      "   [0.37647059 0.58039216 0.80392157]\n",
      "   [0.37647059 0.58039216 0.80392157]\n",
      "   ...\n",
      "   [0.41568627 0.61960784 0.83921569]\n",
      "   [0.41568627 0.61568627 0.83921569]\n",
      "   [0.41568627 0.61960784 0.84313725]]\n",
      "\n",
      "  [[0.38039216 0.58039216 0.80392157]\n",
      "   [0.38823529 0.58823529 0.81176471]\n",
      "   [0.38823529 0.58823529 0.81176471]\n",
      "   ...\n",
      "   [0.41960784 0.61960784 0.84313725]\n",
      "   [0.41960784 0.61960784 0.84313725]\n",
      "   [0.41960784 0.61960784 0.84313725]]\n",
      "\n",
      "  [[0.38431373 0.58431373 0.80784314]\n",
      "   [0.39607843 0.59607843 0.81960784]\n",
      "   [0.39215686 0.59215686 0.81568627]\n",
      "   ...\n",
      "   [0.41960784 0.61960784 0.84313725]\n",
      "   [0.41960784 0.61960784 0.84313725]\n",
      "   [0.41568627 0.61960784 0.84313725]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.82352941 0.75294118 0.63137255]\n",
      "   [0.79607843 0.72156863 0.61568627]\n",
      "   [0.76470588 0.68235294 0.57647059]\n",
      "   ...\n",
      "   [0.69803922 0.61568627 0.43529412]\n",
      "   [0.66666667 0.58823529 0.40784314]\n",
      "   [0.68235294 0.61176471 0.44313725]]\n",
      "\n",
      "  [[0.78823529 0.71372549 0.59215686]\n",
      "   [0.75686275 0.68235294 0.56470588]\n",
      "   [0.7254902  0.64313725 0.53333333]\n",
      "   ...\n",
      "   [0.65490196 0.56078431 0.38431373]\n",
      "   [0.68235294 0.58823529 0.41568627]\n",
      "   [0.66666667 0.57647059 0.40784314]]\n",
      "\n",
      "  [[0.72941176 0.65490196 0.5254902 ]\n",
      "   [0.70588235 0.62352941 0.50196078]\n",
      "   [0.67058824 0.58823529 0.46666667]\n",
      "   ...\n",
      "   [0.63921569 0.5254902  0.36470588]\n",
      "   [0.66666667 0.56078431 0.39215686]\n",
      "   [0.65098039 0.55686275 0.38431373]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10196078 0.10588235 0.1372549 ]\n",
      "   [0.15294118 0.15686275 0.23137255]\n",
      "   [0.15686275 0.16470588 0.21960784]\n",
      "   ...\n",
      "   [0.25490196 0.26666667 0.3372549 ]\n",
      "   [0.26666667 0.27843137 0.35294118]\n",
      "   [0.27058824 0.2745098  0.35686275]]\n",
      "\n",
      "  [[0.10196078 0.10196078 0.13333333]\n",
      "   [0.15294118 0.15686275 0.23137255]\n",
      "   [0.15686275 0.16470588 0.21568627]\n",
      "   ...\n",
      "   [0.26666667 0.27843137 0.34117647]\n",
      "   [0.27843137 0.29019608 0.35686275]\n",
      "   [0.25098039 0.2627451  0.34117647]]\n",
      "\n",
      "  [[0.09803922 0.09803922 0.12941176]\n",
      "   [0.15294118 0.15686275 0.23137255]\n",
      "   [0.14901961 0.15686275 0.20784314]\n",
      "   ...\n",
      "   [0.19215686 0.20392157 0.2627451 ]\n",
      "   [0.26666667 0.27843137 0.34117647]\n",
      "   [0.2627451  0.2745098  0.34117647]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.01176471]\n",
      "   [0.         0.         0.01176471]\n",
      "   [0.         0.         0.01176471]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.00392157 0.00392157]\n",
      "   [0.         0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.00392157]\n",
      "   [0.         0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.00784314]\n",
      "   [0.         0.         0.00392157]\n",
      "   [0.00392157 0.01176471 0.00392157]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.00784314]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.01176471 0.00784314]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.59607843 0.41960784 0.35686275]\n",
      "   [0.72941176 0.52941176 0.43137255]\n",
      "   [0.79215686 0.61176471 0.47843137]\n",
      "   ...\n",
      "   [0.73333333 0.75294118 0.76470588]\n",
      "   [0.6745098  0.69019608 0.70196078]\n",
      "   [0.61568627 0.63529412 0.64313725]]\n",
      "\n",
      "  [[0.5254902  0.37647059 0.31372549]\n",
      "   [0.65490196 0.45490196 0.35686275]\n",
      "   [0.67058824 0.4745098  0.34901961]\n",
      "   ...\n",
      "   [0.27058824 0.29803922 0.30588235]\n",
      "   [0.2745098  0.30588235 0.31372549]\n",
      "   [0.28235294 0.30588235 0.31764706]]\n",
      "\n",
      "  [[0.59607843 0.48627451 0.43921569]\n",
      "   [0.57647059 0.36078431 0.27843137]\n",
      "   [0.62352941 0.41960784 0.29411765]\n",
      "   ...\n",
      "   [0.81176471 0.82745098 0.83921569]\n",
      "   [0.81568627 0.83137255 0.84313725]\n",
      "   [0.81568627 0.82745098 0.83921569]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.21960784 0.01568627 0.00392157]\n",
      "   [0.21960784 0.02352941 0.00784314]\n",
      "   [0.23921569 0.01568627 0.00392157]\n",
      "   ...\n",
      "   [0.74509804 0.53333333 0.48627451]\n",
      "   [0.70196078 0.45098039 0.40784314]\n",
      "   [0.53333333 0.27843137 0.22352941]]\n",
      "\n",
      "  [[0.20392157 0.04313725 0.01176471]\n",
      "   [0.23529412 0.02745098 0.00784314]\n",
      "   [0.30588235 0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.59215686 0.34117647 0.30196078]\n",
      "   [0.62745098 0.27843137 0.24313725]\n",
      "   [0.45098039 0.06666667 0.04313725]]\n",
      "\n",
      "  [[0.25490196 0.00392157 0.        ]\n",
      "   [0.34117647 0.         0.00392157]\n",
      "   [0.50588235 0.03137255 0.05098039]\n",
      "   ...\n",
      "   [0.52156863 0.15294118 0.13333333]\n",
      "   [0.54117647 0.03921569 0.03137255]\n",
      "   [0.60392157 0.00784314 0.02352941]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.41960784 0.34117647 0.23529412]\n",
      "   [0.40784314 0.3372549  0.23137255]\n",
      "   [0.38823529 0.32156863 0.21568627]\n",
      "   ...\n",
      "   [0.69411765 0.7254902  0.7254902 ]\n",
      "   [0.98039216 0.99215686 0.98823529]\n",
      "   [0.99215686 0.98823529 0.99215686]]\n",
      "\n",
      "  [[0.36862745 0.30588235 0.21176471]\n",
      "   [0.34901961 0.29803922 0.21568627]\n",
      "   [0.30588235 0.27058824 0.19215686]\n",
      "   ...\n",
      "   [0.51764706 0.54117647 0.54117647]\n",
      "   [0.96078431 0.96862745 0.96862745]\n",
      "   [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      "  [[0.29019608 0.25490196 0.18823529]\n",
      "   [0.19607843 0.18431373 0.14117647]\n",
      "   [0.1372549  0.14117647 0.11764706]\n",
      "   ...\n",
      "   [0.23529412 0.25098039 0.24705882]\n",
      "   [0.2627451  0.27058824 0.26666667]\n",
      "   [0.23529412 0.23529412 0.23529412]]]]\n",
      "Epoch 1/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 589ms/step - accuracy: 0.5239 - loss: 0.8550 - recall: 0.5196 - val_accuracy: 0.5513 - val_loss: 0.6882 - val_recall: 0.5598\n",
      "Epoch 2/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 585ms/step - accuracy: 0.5672 - loss: 0.6783 - recall: 0.4569 - val_accuracy: 0.5740 - val_loss: 0.6708 - val_recall: 0.5359\n",
      "Epoch 3/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 569ms/step - accuracy: 0.6097 - loss: 0.6669 - recall: 0.6141 - val_accuracy: 0.5421 - val_loss: 0.6831 - val_recall: 0.5072\n",
      "Epoch 4/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 583ms/step - accuracy: 0.6452 - loss: 0.6232 - recall: 0.5543 - val_accuracy: 0.5809 - val_loss: 0.7330 - val_recall: 0.6459\n",
      "Epoch 5/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 571ms/step - accuracy: 0.6890 - loss: 0.5863 - recall: 0.6997 - val_accuracy: 0.5809 - val_loss: 0.7986 - val_recall: 0.6220\n",
      "Epoch 6/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 573ms/step - accuracy: 0.7714 - loss: 0.4763 - recall: 0.7963 - val_accuracy: 0.5626 - val_loss: 0.7457 - val_recall: 0.6507\n",
      "Epoch 7/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 570ms/step - accuracy: 0.8585 - loss: 0.3760 - recall: 0.8909 - val_accuracy: 0.5740 - val_loss: 0.8090 - val_recall: 0.5550\n",
      "Epoch 8/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 573ms/step - accuracy: 0.9187 - loss: 0.2333 - recall: 0.9232 - val_accuracy: 0.5740 - val_loss: 1.5422 - val_recall: 0.5072\n",
      "Epoch 9/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 631ms/step - accuracy: 0.9544 - loss: 0.1368 - recall: 0.9511 - val_accuracy: 0.5809 - val_loss: 1.1663 - val_recall: 0.5742\n",
      "Epoch 10/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 605ms/step - accuracy: 0.9679 - loss: 0.1048 - recall: 0.9670 - val_accuracy: 0.5626 - val_loss: 1.6154 - val_recall: 0.5933\n",
      "Epoch 11/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 604ms/step - accuracy: 0.9863 - loss: 0.0660 - recall: 0.9890 - val_accuracy: 0.5421 - val_loss: 1.8854 - val_recall: 0.5455\n",
      "Epoch 12/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 577ms/step - accuracy: 0.9823 - loss: 0.0583 - recall: 0.9795 - val_accuracy: 0.5626 - val_loss: 2.3558 - val_recall: 0.5359\n",
      "Epoch 13/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 574ms/step - accuracy: 0.9926 - loss: 0.0351 - recall: 0.9920 - val_accuracy: 0.5718 - val_loss: 1.9621 - val_recall: 0.4976\n",
      "Epoch 14/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 587ms/step - accuracy: 0.9620 - loss: 0.1463 - recall: 0.9635 - val_accuracy: 0.5308 - val_loss: 0.8904 - val_recall: 0.4976\n",
      "Epoch 15/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 575ms/step - accuracy: 0.9688 - loss: 0.1610 - recall: 0.9753 - val_accuracy: 0.5923 - val_loss: 0.8174 - val_recall: 0.6890\n",
      "Epoch 16/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 628ms/step - accuracy: 0.9162 - loss: 0.2514 - recall: 0.9332 - val_accuracy: 0.5854 - val_loss: 1.9002 - val_recall: 0.5072\n",
      "Epoch 17/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 602ms/step - accuracy: 0.9905 - loss: 0.0410 - recall: 0.9878 - val_accuracy: 0.5809 - val_loss: 2.0468 - val_recall: 0.5550\n",
      "Epoch 18/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 636ms/step - accuracy: 0.9909 - loss: 0.0416 - recall: 0.9912 - val_accuracy: 0.5626 - val_loss: 2.1075 - val_recall: 0.5789\n",
      "Epoch 19/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 603ms/step - accuracy: 0.9914 - loss: 0.0474 - recall: 0.9946 - val_accuracy: 0.5604 - val_loss: 3.0024 - val_recall: 0.5598\n",
      "Epoch 20/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 617ms/step - accuracy: 0.9911 - loss: 0.0461 - recall: 0.9903 - val_accuracy: 0.5945 - val_loss: 2.2681 - val_recall: 0.5598\n",
      "Epoch 21/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 621ms/step - accuracy: 0.9959 - loss: 0.0179 - recall: 0.9983 - val_accuracy: 0.5718 - val_loss: 2.5738 - val_recall: 0.5072\n",
      "Epoch 22/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 625ms/step - accuracy: 0.9946 - loss: 0.0133 - recall: 0.9911 - val_accuracy: 0.5786 - val_loss: 2.9466 - val_recall: 0.5311\n",
      "Epoch 23/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 607ms/step - accuracy: 0.9971 - loss: 0.0107 - recall: 0.9955 - val_accuracy: 0.5604 - val_loss: 3.5158 - val_recall: 0.5311\n",
      "Epoch 24/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 605ms/step - accuracy: 1.0000 - loss: 0.0013 - recall: 1.0000 - val_accuracy: 0.5718 - val_loss: 3.9999 - val_recall: 0.5455\n",
      "Epoch 25/25\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 607ms/step - accuracy: 1.0000 - loss: 2.5419e-04 - recall: 1.0000 - val_accuracy: 0.5649 - val_loss: 4.2156 - val_recall: 0.5359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe37432b650>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:24:44.827092Z",
     "start_time": "2024-06-28T13:24:43.755462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save(\"faceRecognition.tf.keras\")\n",
    "# Pass the custom objects dictionary to a custom object scope and place\n",
    "# the `keras.models.load_model()` call within the scope."
   ],
   "id": "a0cc19a274d7754b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:08:02.199141Z",
     "start_time": "2024-06-28T13:08:02.148489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = np.array(X1_test[3], dtype = 'float32').reshape(-1, img_size, img_size, 3)\n",
    "x2 = np.array(X2_test[3], dtype = 'float32').reshape(-1, img_size, img_size, 3)\n",
    "\n",
    "print(model.predict([x1, x2]))"
   ],
   "id": "d0361fd292c41978",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3ac545f919323532"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
